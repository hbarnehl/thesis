{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import dateparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting individual lists of lists into single dataframe\n",
    "df = pd.DataFrame(columns = ['page', 'date', 'title', 'text', 'url'])\n",
    "for file in [x for x in glob.glob(\"*\") if x.endswith(\".pkl\")]:\n",
    "    with open(file, \"rb\") as f:\n",
    "        articles = pickle.load(f)\n",
    "    name = file.split(\".\")[0]\n",
    "    df = df.append(pd.DataFrame({\"page\":name, \"title\":articles[1],\n",
    "                                 \"text\":articles[2], \"date\":articles[3],\n",
    "                                 \"url\":articles[0]}))\n",
    "    \n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some preliminary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unify outlet names\n",
    "df.loc[df[\"page\"].str.startswith('Canal13'), \"page\"] = \"Canal13\"\n",
    "df.loc[df[\"page\"].str.startswith('100% Noticias'), \"page\"] = \"100% Noticias\"\n",
    "df.loc[df[\"page\"].str.startswith('Confidencial'), \"page\"] = \"Confidencial\"\n",
    "df.loc[df[\"page\"].str.startswith('Radio Corporacion'), \"page\"] = \"Radio Corporacion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract canal13 dates \n",
    "df.loc[df[\"page\"] == 'Canal13_economia', \"date\"] = df.loc[df[\"page\"] == 'Canal13_economia',\n",
    "                                                          \"url\"].str.extract(r'(\\d\\d\\d\\d/\\d\\d/\\d\\d)').to_numpy()\n",
    "# extract canal 6 dates\n",
    "df.loc[df[\"page\"] == 'Canal6', \"date\"] = df.loc[df[\"page\"] == 'Canal6',\n",
    "                                                \"url\"].str.extract(r'(\\d\\d\\d\\d/\\d\\d/\\d\\d)').to_numpy()\n",
    "# extract radio 800 dates\n",
    "df.loc[df[\"page\"] == 'Radio 800', \"date\"] = df.loc[df[\"page\"] == 'Radio 800',\n",
    "                                                   \"url\"].str.extract(r'(\\d\\d\\d\\d/\\d\\d/\\d\\d)').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hennes/.local/lib/python3.8/site-packages/dateparser/date_parser.py:35: PytzUsageWarning: The localize method is no longer necessary, as this time zone supports the fold attribute (PEP 495). For more details on migrating to a PEP 495-compliant implementation, see https://pytz-deprecation-shim.readthedocs.io/en/latest/migration.html\n",
      "  date_obj = stz.localize(date_obj)\n"
     ]
    }
   ],
   "source": [
    "# convert canal10 date to datetime\n",
    "df10 = df.loc[df[\"page\"] == \"Canal10\"]\n",
    "df10.loc[:,'date'] = df10['date'].str.replace('de ', '', regex=True)\n",
    "df10.loc[:,'date'] = df10['date'].str.replace(r'Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday', '', regex=True)\n",
    "df10.loc[:,'date'] = pd.to_datetime(df10['date'])\n",
    "df.loc[df[\"page\"] == \"Canal10\", 'date'] = df10[\"date\"].to_list()\n",
    "\n",
    "# convert canal14 date to datetime\n",
    "# I am doing that with dateparser, because pandas cannot handle the spanish dates\n",
    "df14 = df.loc[df[\"page\"] == \"Canal14\"]\n",
    "df14.loc[:,'date'] = df14.loc[:,'date'].apply(lambda x: dateparser.parse(x))\n",
    "df.loc[df[\"page\"] == \"Canal14\", 'date'] = df14[\"date\"].to_list()\n",
    "\n",
    "# 100 % noticias\n",
    "df100 = df.loc[df[\"page\"] == \"100% Noticias\"]\n",
    "df100.loc[:,'date'] = df100.loc[:,'date'].apply(lambda x: dateparser.parse(x))\n",
    "df.loc[df[\"page\"] == \"100% Noticias\", 'date'] = df100[\"date\"].to_list()\n",
    "\n",
    "# canal2, canal4, confidencial, radio corporacion, radio nicaragua, radio primerissima are already in datetime format\n",
    "\n",
    "# convert the rest to datetime\n",
    "df.loc[:,\"date\"] = pd.to_datetime(df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Boilerplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "page\n",
       "100% Noticias           18675\n",
       "Canal10                 12332\n",
       "Canal13                 45992\n",
       "Canal14                  6689\n",
       "Canal2                   2636\n",
       "Canal4                  15650\n",
       "Canal6                   5219\n",
       "Confidencial             8112\n",
       "Radio 800                 805\n",
       "Radio Corporacion        9428\n",
       "Radio Nicaragua         21610\n",
       "Radio la Primerisima    14982\n",
       "dtype: int64"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of articles per outlet\n",
    "df.groupby('page').size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
